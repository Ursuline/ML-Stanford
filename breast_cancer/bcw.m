% pkg install -forge iopkg load io%% Initializationclear ; close all; clc%% Setup the parameters input_layer_size  = 30;  % number of variableshidden_layer_size = 10;  % number of hidden unitsnum_labels        = 1;   % 1 or 0% Load CSV filesfilename  = 'breast_cancer_wis.csv';temp      = csv2cell(filename);sz  = size(temp);N   = sz(1,1);header  = temp(1,3:32);     % save header minus empty last cell, id & y valuetemp    = temp(2:end,1:32); % remove empty last column% Convert B to 0 (benign) and M to 1 (Malignant)for i = 1:N-1  if temp{i, 2} == 'B'    temp{i, 2} = 0;  elseif temp{i, 2} == 'M'    temp{i, 2} = 1;  else    temp{i, 2} = NaN;  endifend% Convert cell to matrix formattemp = cell2mat(temp);% extract y value from matrixy = temp(:, 2);% lose the first two columns (id and y value)X = temp(:, 3:32);sz_y = size(y);sz_X = size(X);fprintf('\nInitializing Neural Network Parameters ...\n')initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size);initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels);% Unroll parametersinitial_nn_params = [initial_Theta1(:) ; initial_Theta2(:)];fprintf('\nChecking Cost Function (w/ Regularization) ... \n')% Weight regularization parameter.lambda = 1;J = nnCostFunction(initial_nn_params, input_layer_size, hidden_layer_size,                   num_labels, X, y, lambda)fprintf('\nChecking Backpropagation... \n');%  Check gradients by running checkNNGradientscheckNNGradients;fprintf('\nTraining Neural Network... \n')%  Set MaxIter to a larger value - more training helps.options = optimset('MaxIter', 5);% Create "short hand" for the cost function to be minimizedcostFunction = @(p) nnCostFunction(p,                                   input_layer_size,                                   hidden_layer_size,                                   num_labels, X, y, lambda);% Now, costFunction is a function that takes in only one argument (the% neural network parameters)[nn_params, cost] = fmincg(costFunction, initial_nn_params, options);% Obtain Theta1 and Theta2 back from nn_paramsTheta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)),                 hidden_layer_size, (input_layer_size + 1));Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end),                 num_labels, (hidden_layer_size + 1));sz_Th1 = size(Theta1);sz_Th2 = size(Theta2);pred = predict(Theta1, Theta2, X);size(pred);size(y);%for i = 1:N-1%  printf("%f %f\n", pred(i), y(i))%endfor%mean(pred==y)fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100);